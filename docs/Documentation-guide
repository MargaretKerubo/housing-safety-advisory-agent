# Internal Build Guide – Housing Safety Advisory Agent

> Purpose of this document
> It defines what we are building, how the agent should think, and how code should be structured.
---

## 1. Agent Goal

Build an explainable AI decision-support agent that helps users evaluate accommodation options by reasoning over safety-related trade-offs (commute, time, budget, context) without labeling neighborhoods or making authoritative claims.

---

## 2. What This Agent Is / Is Not

### The agent IS:

* Advisory, not authoritative
* Rule-driven with AI-assisted explanation
* Focused on trade-offs, not predictions
* Context-aware (user profile + constraints)

### The agent IS NOT:

* A crime prediction system
* A neighborhood ranking engine
* A chatbot that gives generic advice
* A system using real crime or surveillance data

---

## 3. Core Design Principles

These principles guide all implementation decisions.

1. Explainability first – every recommendation must be traceable to rules and inputs
2. Ethical neutrality – no stigmatizing language or labels
3. AI as a component – rules decide, AI explains
4. Minimal but structured data – no heavy datasets
5. Deterministic core logic – same inputs → same risk evaluation

---

## 4. High-Level System Flow

1. Collect user inputs
2. Validate inputs and apply guardrails
3. Build / update user session profile
4. Evaluate situational risk using rules
5. Analyze trade-offs and compute scores
6. Generate explanation using AI
7. Return structured recommendation

---

## 5. Key Components to Implement

### 5.1 Input Layer

Responsible for:

* Collecting structured user inputs
* Normalizing values (e.g. budget bands, distance ranges)

Inputs include:

* Location (city/town)
* Budget range
* Commute destination
* Commute distance/time
* Typical return time (day/night)
* Safety tolerance (low / medium / high)
* Living arrangement (alone / shared)

---

### 5.2 Guardrails & Validation Layer

Responsible for:

* Rejecting incomplete inputs
* Refusing unsafe or biased queries
* Reframing problematic requests

Examples:

* Refuse: “Which areas are dangerous?”
* Reframe to: “I can help you compare housing options based on situational risk factors.”

---

### 5.3 User Profile & Session State

Responsible for:

* Persisting user preferences during a session
* Allowing multi-step interaction

State includes:

* Risk tolerance
* Budget constraints
* Commute preferences

---

### 5.4 Rule-Based Risk Evaluation Engine

Responsible for:

* Applying predefined rules
* Producing a numeric or categorical risk score

Rules consider:

* Time of travel
* Commute length
* Transport availability
* Living alone vs shared

Example rule:

* If return_time = night AND commute_distance > threshold → increase risk

This component must not use AI.

---

### 5.5 Scoring & Trade-Off Analyzer

Responsible for:

* Aggregating rule outputs
* Balancing safety vs cost vs convenience
* Producing comparable option scores

Outputs:

* Risk level (Low / Medium / Higher)
* Key trade-offs identified

---

### 5.6 AI Reasoning & Explanation Layer

Responsible for:

* Translating scores into natural language
* Explaining *why* one option is preferred
* Communicating uncertainty and limitations

AI does not:

* Decide risk levels
* Override rule outputs

AI does:

* Explain decisions
* Summarize reasoning
* Answer “why / why not” questions

---

### 5.7 Output Formatter

Responsible for:

* Producing final user-facing response
* Supporting both human-readable text and structured output

---

## 6. Data Strategy

* No real crime datasets
* No real-time feeds
* Use small, static, explainable reference values

All assumptions must be documented in code comments.

---

## 7. Ethical Constraints (Hard Rules)

The system must:

* Never label areas as safe or unsafe
* Never rank neighborhoods by crime
* Avoid demographic or socioeconomic assumptions
* Include advisory disclaimers in outputs

---

## 8. What Success Looks Like (For Us)

* Clean separation of components
* Deterministic core logic
* Clear explanation of every recommendation
* Easy-to-follow demo flow
* Code that matches this document

---

## 9. What Comes Next (After This Doc)

1. Define input/output schemas
2. Implement rule engine
3. Add AI explanation layer
4. Build CLI or simple UI
5. Write README for judges

---

> Reminder: If a feature does not support decision-making or explainability, it does not belong in this agent.
